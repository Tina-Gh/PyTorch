{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Tensors:"
      ],
      "metadata": {
        "id": "SmWCRrRP_Awx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "uBDnNlsyvbzX"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LJOEUw7zvTFc",
        "outputId": "649b5e5f-03cd-4dc7-8e3f-24020322c2cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 2, 3])\n",
            "torch.int64\n",
            "torch.Size([3])\n"
          ]
        }
      ],
      "source": [
        "a = torch.tensor([1, 2, 3])\n",
        "print(a)\n",
        "print(a.dtype) #torch default is float64\n",
        "print(a.shape) #this is just the shape; it's different from the dimension (aka. rank)!\n",
        "#\"a\" has a shape of 3 but it has a dimension (or rank) of 1 (aka. a 1D tensor)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a_floated = torch.tensor([1.0, 2.0, 3.0])\n",
        "print(a_floated)\n",
        "print(a_floated.dtype) #torch floated default is float32. THis is the ideal dtype for GPUs."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xa1HOTj1vbAZ",
        "outputId": "3b5ee38f-eaa5-47d8-8afc-1941158f2eac"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 2., 3.])\n",
            "torch.float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b = a.to(torch.float32)\n",
        "print(b)\n",
        "print(b.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZ3ouB2hvUdE",
        "outputId": "36212a46-21cb-425b-acda-93d65fb6b699"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 2., 3.])\n",
            "torch.float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a_t = a.T\n",
        "print(a_t)\n",
        "print(a_t.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QzAbGUTwvUjx",
        "outputId": "27a9ae70-a563-4723-9725-05434cca8a1f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 2, 3])\n",
            "torch.Size([3])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-ac249b888bae>:1: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at /pytorch/aten/src/ATen/native/TensorShape.cpp:3725.)\n",
            "  a_t = a.T\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# .matmul is the same method as @\n",
        "\n",
        "mat_1 = torch.tensor([[1, 2, 3],\n",
        "                      [4, 5, 6]], dtype=torch.float32)\n",
        "print(\"mat_1: \\n\", mat_1)\n",
        "print(mat_1.shape)\n",
        "print(mat_1.dtype)\n",
        "print(\"\\n\")\n",
        "\n",
        "mat_2 = torch.tensor([[7, 8, 9],\n",
        "                     [10, 11, 12]], dtype=torch.float32)\n",
        "print(\"mat_2: \\n\", mat_2)\n",
        "print(mat_2.dtype)\n",
        "print(mat_2.shape)\n",
        "print(\"\\n\")\n",
        "\n",
        "mat_multpl_1 = mat_1 * mat_2 # This is element-wise matrix multiplication.\n",
        "print(\"the * operation: \\n\", mat_multpl_1)\n",
        "print(\"\\n\")\n",
        "\n",
        "mat_multpl_2 = mat_1.matmul(mat_2.T) # This is the typical algbra matrix multiolication (aka. times).\n",
        "print(\"the matmul operation: \\n\", mat_multpl_2)\n",
        "print(\"\\n\")\n",
        "\n",
        "mat_multpl_3 = mat_1 @ mat_2.T # Same as .matmul\n",
        "print(\"the @ operation: \\n\", mat_multpl_3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RjAJRLAsvUp6",
        "outputId": "2f432096-a2b4-4bab-e745-fc80ccb61162"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mat_1: \n",
            " tensor([[1., 2., 3.],\n",
            "        [4., 5., 6.]])\n",
            "torch.Size([2, 3])\n",
            "torch.float32\n",
            "\n",
            "\n",
            "mat_2: \n",
            " tensor([[ 7.,  8.,  9.],\n",
            "        [10., 11., 12.]])\n",
            "torch.float32\n",
            "torch.Size([2, 3])\n",
            "\n",
            "\n",
            "the * operation: \n",
            " tensor([[ 7., 16., 27.],\n",
            "        [40., 55., 72.]])\n",
            "\n",
            "\n",
            "the matmul operation: \n",
            " tensor([[ 50.,  68.],\n",
            "        [122., 167.]])\n",
            "\n",
            "\n",
            "the @ operation: \n",
            " tensor([[ 50.,  68.],\n",
            "        [122., 167.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"a: \\n\", a, \"\\n\", a.shape)\n",
        "print(\"\\n\")\n",
        "\n",
        "a_reshaped_1 = a.reshape(1, 3)\n",
        "print(\"reshaped a: \\n\", a_reshaped_1, \"\\n\", a_reshaped_1.shape)\n",
        "print(\"\\n\")\n",
        "\n",
        "a_reshaped_2 = a.reshape(3, 1)\n",
        "print(\"reshaped a: \\n\", a_reshaped_2, \"\\n\", a_reshaped_2.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gXjeEbHnyF0t",
        "outputId": "685b3db3-bd54-4e4c-b2ba-4410c9f0a71e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a: \n",
            " tensor([1, 2, 3]) \n",
            " torch.Size([3])\n",
            "\n",
            "\n",
            "reshaped a: \n",
            " tensor([[1, 2, 3]]) \n",
            " torch.Size([1, 3])\n",
            "\n",
            "\n",
            "reshaped a: \n",
            " tensor([[1],\n",
            "        [2],\n",
            "        [3]]) \n",
            " torch.Size([3, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Autograd: PyTorch's automatic differentiation engine ->\n",
        "### 1. Manual: the \"grad\" function\n",
        "### 2. Automatic: the \"backward\" function and the \"grad\" attribute"
      ],
      "metadata": {
        "id": "Bc9cg8wY_F18"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#This is the forward pass of a simple logistic regression classifier: (MANUAL:)\n",
        "\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import grad\n",
        "\n",
        "y = torch.tensor([1.0]) #true label\n",
        "x1 = torch.tensor([1.1])\n",
        "w1 = torch.tensor([2.2], requires_grad=True)\n",
        "b = torch.tensor([0.0], requires_grad=True)\n",
        "\n",
        "z = x1 * w1 + b\n",
        "a = torch.sigmoid(z)\n",
        "\n",
        "loss = F.binary_cross_entropy(a, y)\n",
        "\n",
        "grad_L_w1 = grad(loss, w1, retain_graph=True)\n",
        "grad_L_b = grad(loss, b, retain_graph=True)\n",
        "\n",
        "print(grad_L_w1)\n",
        "print(grad_L_b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZGcSrXlr357n",
        "outputId": "59cce898-08a4-4257-99d9-6b933961ada5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(tensor([-0.0898]),)\n",
            "(tensor([-0.0817]),)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# (AUTOMATIC:)\n",
        "\n",
        "loss.backward()\n",
        "print(w1.grad)\n",
        "print(b.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aS2ugzwA_Rff",
        "outputId": "25fdcac8-544d-41e8-d8a6-c12d966e310c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-0.0898])\n",
            "tensor([-0.0817])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Multilayer neural networks: (no training yet)"
      ],
      "metadata": {
        "id": "I7syhPW1gLXd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetwork(torch.nn.Module):\n",
        "  def __init__(self, num_inputs, num_outputs):\n",
        "    super().__init__()\n",
        "\n",
        "    self.layers = torch.nn.Sequential(\n",
        "        #1st hidden layer\n",
        "        torch.nn.Linear(num_inputs, 30),\n",
        "        torch.nn.ReLU(),\n",
        "\n",
        "        #2nd hidden layer\n",
        "        torch.nn.Linear(30, 20),\n",
        "        torch.nn.ReLU(),\n",
        "\n",
        "        #output layer\n",
        "        torch.nn.Linear(20, num_outputs),\n",
        "    )\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    logits = self.layers(x)\n",
        "    return logits"
      ],
      "metadata": {
        "id": "7w2ScPbX_SIZ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "model = NeuralNetwork(50, 3)\n",
        "print(model)\n",
        "print(model.layers)\n",
        "print(model.layers[0].weight)\n",
        "print(model.layers[0].weight.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pR09ZFnRakNE",
        "outputId": "ef95e8a9-0b2a-4618-ef0e-f738299f9cbd"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NeuralNetwork(\n",
            "  (layers): Sequential(\n",
            "    (0): Linear(in_features=50, out_features=30, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=30, out_features=20, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=20, out_features=3, bias=True)\n",
            "  )\n",
            ")\n",
            "Sequential(\n",
            "  (0): Linear(in_features=50, out_features=30, bias=True)\n",
            "  (1): ReLU()\n",
            "  (2): Linear(in_features=30, out_features=20, bias=True)\n",
            "  (3): ReLU()\n",
            "  (4): Linear(in_features=20, out_features=3, bias=True)\n",
            ")\n",
            "Parameter containing:\n",
            "tensor([[-0.0577,  0.0047, -0.0702,  ...,  0.0222,  0.1260,  0.0865],\n",
            "        [ 0.0502,  0.0307,  0.0333,  ...,  0.0951,  0.1134, -0.0297],\n",
            "        [ 0.1077, -0.1108,  0.0122,  ...,  0.0108, -0.1049, -0.1063],\n",
            "        ...,\n",
            "        [-0.0787,  0.1259,  0.0803,  ...,  0.1218,  0.1303, -0.1351],\n",
            "        [ 0.1359,  0.0175, -0.0673,  ...,  0.0674,  0.0676,  0.1058],\n",
            "        [ 0.0790,  0.1343, -0.0293,  ...,  0.0344, -0.0971, -0.0509]],\n",
            "       requires_grad=True)\n",
            "torch.Size([30, 50])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(\"Total number of trainable parameters: \", num_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1XGEFIo2yHkv",
        "outputId": "bad1a03f-97b3-47b2-b74a-d174b7972b5a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of trainable parameters:  2213\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now with example input:\n",
        "torch.manual_seed(123)\n",
        "X = torch.rand((1, 50))\n",
        "out = model(X)\n",
        "print(out)\n",
        "\n",
        "# A more efficient way is to not calculate gradients if we are not doing any training/backpropagation (aka. we are doing inference/predictin):\n",
        "with torch.no_grad():\n",
        "  out = model(X)\n",
        "print(out)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RMKAMvAtyQk9",
        "outputId": "140caa65-ffc7-4fcb-d028-e56d9637c3c6"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.1262,  0.1080, -0.1792]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[-0.1262,  0.1080, -0.1792]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Dataset and Dataloader classes:"
      ],
      "metadata": {
        "id": "1m2LzQ3U7JrF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = torch.tensor([\n",
        "    [-1.2, 3.1],\n",
        "    [-0.9, 2.9],\n",
        "    [-0.5, 2.6],\n",
        "    [2.3, -1.1],\n",
        "    [2.7, -1.5]\n",
        "])\n",
        "\n",
        "y_train = torch.tensor([0, 0, 0, 1, 1])\n",
        "\n",
        "x_test = torch.tensor([\n",
        "    [-0.8, 2.8],\n",
        "    [2.6, -1.6]\n",
        "])\n",
        "\n",
        "y_test = torch.tensor([0, 1])"
      ],
      "metadata": {
        "id": "t-gc9LpoGdFZ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class Dataset(Dataset):\n",
        "  def __init__(self, X, y):\n",
        "    self.features = X\n",
        "    self.labels = y\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    one_x = self.features[index]\n",
        "    one_y = self.labels[index]\n",
        "    return one_x, one_y\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.labels.shape[0] #[0] makes it so that it returns the digit, not torch.tensor(digit) as the vector shape.\n",
        "\n",
        "train_ds = Dataset(X_train, y_train)\n",
        "test_ds = Dataset(x_test, y_test)"
      ],
      "metadata": {
        "id": "6_-2HJIOakRc"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    dataset=train_ds,\n",
        "    batch_size=2,\n",
        "    shuffle=True,\n",
        "    num_workers=0, #background processes\n",
        "    drop_last=True #optional: helps with dropping the last no-deviadle batch size to prevent disturbances to convergence\n",
        ")\n",
        "\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    dataset=test_ds,\n",
        "    batch_size=2,\n",
        "    shuffle=False, #there is no need to shuffle test data\n",
        "    num_workers=0\n",
        ")\n",
        "\n",
        "for idx, (x, y) in enumerate(train_loader):\n",
        "  print(f\"Batch {idx+1}: \", x, y)"
      ],
      "metadata": {
        "id": "5YafrG53akdH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d1b3525-832b-47c1-ac4b-41c4c6cb8e56"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 1:  tensor([[ 2.3000, -1.1000],\n",
            "        [-0.9000,  2.9000]]) tensor([1, 0])\n",
            "Batch 2:  tensor([[-1.2000,  3.1000],\n",
            "        [-0.5000,  2.6000]]) tensor([0, 0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. A typical training loop:\n"
      ],
      "metadata": {
        "id": "Bm_swKTIMcFl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F #for loss\n",
        "\n",
        "torch.manual_seed(123)\n",
        "model = NeuralNetwork(num_inputs=2, num_outputs=2)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.5)\n",
        "\n",
        "num_epochs = 3\n",
        "for epoch in range(num_epochs): #in each epoch\n",
        "\n",
        "  model.train() #initialize the model for training\n",
        "  for batch_idx, (features, labels) in enumerate(train_loader): #make the baches\n",
        "    logits = model(features)\n",
        "\n",
        "    loss = F.cross_entropy(logits, labels) #calculate loss\n",
        "    optimizer.zero_grad() #zero the previous gradients\n",
        "    loss.backward() #calculate the gradients\n",
        "    optimizer.step() #apply the gradients\n",
        "\n",
        "    #logging:\n",
        "    print(f\"Epoch: {epoch+1:03d}/{num_epochs:03d}\" f\" | Batch: {batch_idx+1:03d}/{len(train_loader):03d}\" f\" | Train Loss: {loss:.2f}\")"
      ],
      "metadata": {
        "id": "i69TUc8yMIF_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7312d48c-2b61-45e8-f7b1-f9b879af88b4"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 001/003 | Batch: 001/002 | Train Loss: 0.75\n",
            "Epoch: 001/003 | Batch: 002/002 | Train Loss: 0.65\n",
            "Epoch: 002/003 | Batch: 001/002 | Train Loss: 0.44\n",
            "Epoch: 002/003 | Batch: 002/002 | Train Loss: 0.13\n",
            "Epoch: 003/003 | Batch: 001/002 | Train Loss: 0.03\n",
            "Epoch: 003/003 | Batch: 002/002 | Train Loss: 0.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "#insert optional model evaluation code.\n",
        "with torch.no_grad():\n",
        "  outputs = model(X_train) #obviously using train data isn't wise. but this is just for practice.\n",
        "print(outputs)\n",
        "\n",
        "output_argmax = torch.argmax(outputs, dim=1)\n",
        "print(output_argmax)"
      ],
      "metadata": {
        "id": "G7lUkEZ-MIIV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e44d58e-62a0-4adf-cdfc-f1a9699a940f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 2.8569, -4.1618],\n",
            "        [ 2.5382, -3.7548],\n",
            "        [ 2.0944, -3.1820],\n",
            "        [-1.4814,  1.4816],\n",
            "        [-1.7176,  1.7342]])\n",
            "tensor([0, 0, 0, 1, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "probabs = torch.softmax(outputs, dim=1)\n",
        "\n",
        "torch.set_printoptions(sci_mode=False) #to make the putput more legible (aka. without the sci notation of e to the power of...)\n",
        "print(probabs)\n",
        "\n",
        "preds = torch.argmax(probabs, dim=1)\n",
        "print(preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QqtSCfljpA6Z",
        "outputId": "790ea47c-4f8e-4ce3-85c5-85840005e877"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[    0.9991,     0.0009],\n",
            "        [    0.9982,     0.0018],\n",
            "        [    0.9949,     0.0051],\n",
            "        [    0.0491,     0.9509],\n",
            "        [    0.0307,     0.9693]])\n",
            "tensor([0, 0, 0, 1, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# calculating prediction acuracy:\n",
        "\n",
        "def compute_accuracy(model, dataloader):\n",
        "  model = model.eval()\n",
        "  correct = 0.0\n",
        "  total_examples = 0\n",
        "\n",
        "  for idx, (features, labels) in enumerate(dataloader):\n",
        "    with torch.no_grad():\n",
        "      logits = model(features)\n",
        "\n",
        "    predictions = torch.argmax(logits, dim=1)\n",
        "    compare = labels == predictions\n",
        "    correct += torch.sum(compare)\n",
        "    total_examples += len(compare)\n",
        "\n",
        "  return (correct/total_examples).item()\n",
        "\n",
        "\n",
        "print(compute_accuracy(model, train_loader))\n",
        "print(compute_accuracy(model, test_loader))"
      ],
      "metadata": {
        "id": "aY8y2bbTqYIR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37452b40-e8a9-4b0b-d25f-ffa0edc6659c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n",
            "1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#saving the model:\n",
        "\n",
        "torch.save(model.state_dict(), \"model.pth\") # .state_dict() maps each layr in the model to its trainable parameters.\n",
        "\n",
        "#to restore the model from disk (aka. calling the model):\n",
        "model = NeuralNetwork(2, 2) # this ine is not strictly necessary if we are executing it in the same session where we saved the model.\n",
        "#But otherwise, we do need it as an instance of the model in the memory to apply saved parameters to.\n",
        "model.load_state_dict(torch.load(\"model.pth\"))\n",
        "# .load() reads the provided file and reconstruct the model's parameters.\n",
        "# .load_state_dict() applies these parameters to the model."
      ],
      "metadata": {
        "id": "4TwsGtWOqYQ0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3386a427-ba65-419d-f807-b73afe5a2f9a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Single-GPU training: (addding 3 lines of code to the model in section 5)"
      ],
      "metadata": {
        "id": "IAGDr2X0qP7p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.cuda.is_available())"
      ],
      "metadata": {
        "id": "mX1G7M4apA8R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9bead23-89f5-4b91-85f1-b720fdcf00d3"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_1 = torch.tensor([1., 2., 3.])\n",
        "tensor_2 = torch.tensor([4., 5., 6.])\n",
        "\n",
        "print(tensor_1 + tensor_2) #this runs on CPU by default.\n",
        "\n",
        "tensor_1 = tensor_1.to(\"cuda\")\n",
        "tensor_2 = tensor_2.to(\"cuda\")\n",
        "print(tensor_1 + tensor_2)"
      ],
      "metadata": {
        "id": "OiLb8QPHpA-Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0addde47-24e8-4c03-879b-8ce33028a33f"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([5., 7., 9.])\n",
            "tensor([5., 7., 9.], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The previous model, this time being trained on GPU:\n",
        "\n",
        "torch.manual_seed(123)\n",
        "device = torch.device(\"cuda\")\n",
        "# or:\n",
        "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = NeuralNetwork(num_inputs=2, num_outputs=2)\n",
        "model.to(device)\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.5)\n",
        "\n",
        "num_epochs=3\n",
        "for epoch in range(num_epochs):\n",
        "  model.train()\n",
        "\n",
        "  for batch_idx, (features, labels) in enumerate(train_loader):\n",
        "    features, labels = features.to(device), labels.to(device)\n",
        "    logits = model(features)\n",
        "\n",
        "    loss = F.cross_entropy(logits, labels)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    #logging:\n",
        "    print(f\"Epoch: {epoch+1:03d}/{num_epochs:03d}\" f\" | Batch: {batch_idx+1:03d}/{len(train_loader):03d}\" f\" | Train/Val Loss: {loss:.2f}\")\n",
        "\n",
        "  model.eval()\n",
        "  #insert evaluation section here."
      ],
      "metadata": {
        "id": "ee0UmORZpBL0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "649ca956-d17f-4be0-cd83-a893a7cd3e71"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 001/003 | Batch: 001/002 | Train/Val Loss: 0.75\n",
            "Epoch: 001/003 | Batch: 002/002 | Train/Val Loss: 0.65\n",
            "Epoch: 002/003 | Batch: 001/002 | Train/Val Loss: 0.44\n",
            "Epoch: 002/003 | Batch: 002/002 | Train/Val Loss: 0.13\n",
            "Epoch: 003/003 | Batch: 001/002 | Train/Val Loss: 0.03\n",
            "Epoch: 003/003 | Batch: 002/002 | Train/Val Loss: 0.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. Multi-GPU training: -> Interative platforms such as Jupyter notebooks don't handle multiprocessing the same way as Python scripts do. So, for this section, refer to the following GitHub for the Python script: (Book Author's GitHub page)\n",
        "\n",
        "https://github.com/rasbt/LLMs-from-scratch/tree/main/appendix-A/01_main-chapter-code"
      ],
      "metadata": {
        "id": "kQ1rfTfuKBII"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xbf3mFV9pBPR"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "28TOXGNmrlGG"
      },
      "execution_count": 24,
      "outputs": []
    }
  ]
}