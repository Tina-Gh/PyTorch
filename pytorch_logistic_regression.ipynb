{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Logistic Regression with PyTorch\n",
    "## 1. About Logistic Regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 1.1 Logistic Regression Basics\n",
    "\n",
    "#### Classification algorithm\n",
    "- Example: Spam vs No Spam\n",
    "    - Input: Bunch of words\n",
    "    - Output: Probability spam or not\n",
    "\n",
    "#### Basic Comparison\n",
    "- **Linear regression**\n",
    "    - Output: numeric value given inputs\n",
    "- **Logistic regression**:\n",
    "    - Output: probability [0, 1] given input belonging to a class\n",
    "    \n",
    "    \n",
    "#### Input/Output Comparison\n",
    "- **Linear regression: Multiplication**\n",
    "    - Input: [1]\n",
    "        - Output: 2\n",
    "    - Input: [2]\n",
    "        - Output: 4\n",
    "    - Trying to model the relationship `y = 2x`\n",
    "- **Logistic regression: Spam**\n",
    "    - Input: \"Sign up to get 1 million dollars by tonight\"\n",
    "        - Output: p = 0.8\n",
    "    - Input: \"This is a receipt for your recent purchase with Amazon\"\n",
    "        - Output: p = 0.3\n",
    "    - **p: probability it is spam**\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Problems of Linear Regression\n",
    "- Example\n",
    "    - Fever\n",
    "    - **Input**: temperature\n",
    "    - **Output**: fever or no fever\n",
    "- Remember\n",
    "    - **Linear regression**: minimize error between points and line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "x = [1, 5, 10, 10, 25, 50, 70, 75, 100]\n",
    "y = [0, 0, 0, 0, 0, 1, 1, 1, 1]\n",
    "\n",
    "colors = np.random.rand(len(x))\n",
    "plt.plot(np.unique(x), np.poly1d(np.polyfit(x, y, 1))(np.unique(x)))\n",
    "plt.ylabel(\"Fever\")\n",
    "plt.xlabel(\"Temperature\")\n",
    "\n",
    "plt.scatter(x, y, c=colors, alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Linear Regression Problem 1**\n",
    "<br> Fever value can go negative (below 0) and positive (above 1).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = [1, 5, 10, 10, 25, 50, 70, 75, 300]\n",
    "y = [0, 0, 0, 0, 0, 1, 1, 1, 1]\n",
    "\n",
    "colors = np.random.rand(len(x))\n",
    "plt.plot(np.unique(x), np.poly1d(np.polyfit(x, y, 1))(np.unique(x)))\n",
    "plt.ylabel(\"Fever\")\n",
    "plt.xlabel(\"Temperature\")\n",
    "\n",
    "plt.scatter(x, y, c=colors, alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Linear Regression Problem 2**\n",
    "<br> Fever points not predicted with outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Logistic Regression In-Depth\n",
    "\n",
    "#### Predicting Probability\n",
    "- Linear regression doesn't work\n",
    "- Instead of predicting direct values: **predict probability**\n",
    "\n",
    "<img src=\"./images/cross_entropy_final_4.png\" alt=\"deeplearningwizard\" style=\"width: 900px;\"/>\n",
    "\n",
    "#### Logistic Function $g()$ \n",
    "- Two-class logistic regression\n",
    "- $ y = A x + b$\n",
    "- $ g(y) = A x + b $\n",
    "- $g(y) = \\frac {1} {1 + e^{-y}} = \\frac {1} {1 + e^{-(A x + b)}}$\n",
    "- $g(y)$ = Estimated probability that $y = 1$ given $x$\n",
    "\n",
    "\n",
    "#### Softmax Function $g()$ \n",
    "- Multi-class logistic regression\n",
    "- Generalization of logistic function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross Entropy Function $D()$\n",
    "- $D(S, L) = L log S - (1-L)log(1-S)$\n",
    "    - If L = 0 (label)\n",
    "        - $D(S, 0) = - log(1-S)$\n",
    "            - $- log(1-S)$: less positive if $S \\longrightarrow 0 $\n",
    "            - $- log(1-S)$: more positive if $S \\longrightarrow 1 $ (BIGGER LOSS)\n",
    "    - If L = 1 (label)\n",
    "        - $D(S, 1) = log S$\n",
    "            - $logS$: less negative if $S \\longrightarrow 1 $\n",
    "            - $logS$: more negative if $S \\longrightarrow 0 $ (BIGGER LOSS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0000050000287824e-05\n",
      "11.51292546497478\n",
      "-1.0000050000287824e-05\n",
      "-11.512925464970229\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "print(-math.log(1 - 0.00001))\n",
    "print(-math.log(1 - 0.99999))\n",
    "\n",
    "print(math.log(0.99999))\n",
    "print(math.log(0.00001))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross Entropy Loss $L$\n",
    "- Goal: Minimizing Cross Entropy Loss\n",
    "- $ L = \\frac {1}{N} \\sum_i D(g(Ax_i + b), L_i)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Building a Logistic Regression Model with PyTorch\n",
    "\n",
    "<img src=\"./images/lr2.png\" alt=\"deeplearningwizard\" style=\"width: 900px;\"/>\n",
    "\n",
    "### Steps\n",
    "- Step 1: Load Dataset\n",
    "- Step 2: Make Dataset Iterable\n",
    "- Step 3: Create Model Class\n",
    "- Step 4: Instantiate Model Class\n",
    "- Step 5: Instantiate Loss Class\n",
    "- Step 6: Instantiate Optimizer Class\n",
    "- Step 7: Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1a: Loading MNIST Train Dataset\n",
    "**Images from 1 to 9**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_dataset = dsets.MNIST(root='./data', \n",
    "                            train=True, \n",
    "                            transform=transforms.ToTensor(),\n",
    "                            download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0118,  0.0706,\n",
       "            0.0706,  0.0706,  0.4941,  0.5333,  0.6863,  0.1020,  0.6510,\n",
       "            1.0000,  0.9686,  0.4980,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000,  0.1176,  0.1412,  0.3686,  0.6039,  0.6667,  0.9922,\n",
       "            0.9922,  0.9922,  0.9922,  0.9922,  0.8824,  0.6745,  0.9922,\n",
       "            0.9490,  0.7647,  0.2510,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.1922,  0.9333,  0.9922,  0.9922,  0.9922,  0.9922,  0.9922,\n",
       "            0.9922,  0.9922,  0.9922,  0.9843,  0.3647,  0.3216,  0.3216,\n",
       "            0.2196,  0.1529,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0706,  0.8588,  0.9922,  0.9922,  0.9922,  0.9922,  0.9922,\n",
       "            0.7765,  0.7137,  0.9686,  0.9451,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000,  0.3137,  0.6118,  0.4196,  0.9922,  0.9922,  0.8039,\n",
       "            0.0431,  0.0000,  0.1686,  0.6039,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000,  0.0000,  0.0549,  0.0039,  0.6039,  0.9922,  0.3529,\n",
       "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000,  0.0000,  0.0000,  0.0000,  0.5451,  0.9922,  0.7451,\n",
       "            0.0078,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000,  0.0000,  0.0000,  0.0000,  0.0431,  0.7451,  0.9922,\n",
       "            0.2745,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.1373,  0.9451,\n",
       "            0.8824,  0.6275,  0.4235,  0.0039,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.3176,\n",
       "            0.9412,  0.9922,  0.9922,  0.4667,  0.0980,  0.0000,  0.0000,\n",
       "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.1765,  0.7294,  0.9922,  0.9922,  0.5882,  0.1059,  0.0000,\n",
       "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000,  0.0627,  0.3647,  0.9882,  0.9922,  0.7333,  0.0000,\n",
       "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000,  0.0000,  0.0000,  0.9765,  0.9922,  0.9765,  0.2510,\n",
       "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.1804,  0.5098,  0.7176,  0.9922,  0.9922,  0.8118,  0.0078,\n",
       "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.1529,  0.5804,\n",
       "            0.8980,  0.9922,  0.9922,  0.9922,  0.9804,  0.7137,  0.0000,\n",
       "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000,  0.0000,  0.0000,  0.0941,  0.4471,  0.8667,  0.9922,\n",
       "            0.9922,  0.9922,  0.9922,  0.7882,  0.3059,  0.0000,  0.0000,\n",
       "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000,  0.0902,  0.2588,  0.8353,  0.9922,  0.9922,  0.9922,\n",
       "            0.9922,  0.7765,  0.3176,  0.0078,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0706,\n",
       "            0.6706,  0.8588,  0.9922,  0.9922,  0.9922,  0.9922,  0.7647,\n",
       "            0.3137,  0.0353,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.2157,  0.6745,  0.8863,\n",
       "            0.9922,  0.9922,  0.9922,  0.9922,  0.9569,  0.5216,  0.0431,\n",
       "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.5333,  0.9922,  0.9922,\n",
       "            0.9922,  0.8314,  0.5294,  0.5176,  0.0627,  0.0000,  0.0000,\n",
       "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]]]),\n",
       " tensor(5))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input Matrix\n",
    "train_dataset[0][0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Label\n",
    "train_dataset[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Displaying MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 28, 28)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0][0].numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "show_img = train_dataset[0][0].numpy().reshape(28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7ff7c871db70>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAADgpJREFUeJzt3X+MVfWZx/HPs1j+kKI4aQRCYSnEYJW4082IjSWrxkzVDQZHrekkJjQapn8wiU02ZA3/VNNgyCrslmiamaZYSFpKE3VB0iw0otLGZuKIWC0srTFsO3IDNTjywx9kmGf/mEMzxbnfe+fec++5zPN+JeT+eM6558kNnznn3O+592vuLgDx/EPRDQAoBuEHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxDUZc3cmJlxOSHQYO5u1SxX157fzO40syNm9q6ZPVrPawFoLqv12n4zmybpj5I6JQ1Jel1St7sfSqzDnh9osGbs+ZdJetfd33P3c5J+IWllHa8HoInqCf88SX8Z93goe+7vmFmPmQ2a2WAd2wKQs3o+8Jvo0OJzh/Xu3i+pX+KwH2gl9ez5hyTNH/f4y5KO1dcOgGapJ/yvS7rGzL5iZtMlfVvSrnzaAtBoNR/2u/uImfVK2iNpmqQt7v6H3DoD0FA1D/XVtDHO+YGGa8pFPgAuXYQfCIrwA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8EVfMU3ZJkZkclnZZ0XtKIu3fk0RTyM23atGT9yiuvbOj2e3t7y9Yuv/zy5LpLlixJ1tesWZOsP/XUU2Vr3d3dyXU//fTTZH3Dhg3J+uOPP56st4K6wp+5zd0/yOF1ADQRh/1AUPWG3yXtNbM3zKwnj4YANEe9h/3fcPdjZna1pF+b2f+6+/7xC2R/FPjDALSYuvb87n4suz0h6QVJyyZYpt/dO/gwEGgtNYffzGaY2cwL9yV9U9I7eTUGoLHqOeyfLekFM7vwOj939//JpSsADVdz+N39PUn/lGMvU9aCBQuS9enTpyfrN998c7K+fPnysrVZs2Yl173vvvuS9SINDQ0l65s3b07Wu7q6ytZOnz6dXPett95K1l999dVk/VLAUB8QFOEHgiL8QFCEHwiK8ANBEX4gKHP35m3MrHkba6L29vZkfd++fcl6o79W26pGR0eT9YceeihZP3PmTM3bLpVKyfqHH36YrB85cqTmbTeau1s1y7HnB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgGOfPQVtbW7I+MDCQrC9atCjPdnJVqffh4eFk/bbbbitbO3fuXHLdqNc/1ItxfgBJhB8IivADQRF+ICjCDwRF+IGgCD8QVB6z9IZ38uTJZH3t2rXJ+ooVK5L1N998M1mv9BPWKQcPHkzWOzs7k/WzZ88m69dff33Z2iOPPJJcF43Fnh8IivADQRF+ICjCDwRF+IGgCD8QFOEHgqr4fX4z2yJphaQT7r40e65N0g5JCyUdlfSAu6d/6FxT9/v89briiiuS9UrTSff19ZWtPfzww8l1H3zwwWR9+/btyTpaT57f5/+ppDsveu5RSS+5+zWSXsoeA7iEVAy/u++XdPElbCslbc3ub5V0T859AWiwWs/5Z7t7SZKy26vzawlAMzT82n4z65HU0+jtAJicWvf8x81sriRltyfKLeju/e7e4e4dNW4LQAPUGv5dklZl91dJ2plPOwCapWL4zWy7pN9JWmJmQ2b2sKQNkjrN7E+SOrPHAC4hFc/53b27TOn2nHsJ69SpU3Wt/9FHH9W87urVq5P1HTt2JOujo6M1bxvF4go/ICjCDwRF+IGgCD8QFOEHgiL8QFBM0T0FzJgxo2ztxRdfTK57yy23JOt33XVXsr53795kHc3HFN0Akgg/EBThB4Ii/EBQhB8IivADQRF+ICjG+ae4xYsXJ+sHDhxI1oeHh5P1l19+OVkfHBwsW3vmmWeS6zbz/+ZUwjg/gCTCDwRF+IGgCD8QFOEHgiL8QFCEHwiKcf7gurq6kvVnn302WZ85c2bN2163bl2yvm3btmS9VCrVvO2pjHF+AEmEHwiK8ANBEX4gKMIPBEX4gaAIPxBUxXF+M9siaYWkE+6+NHvuMUmrJf01W2ydu/+q4sYY57/kLF26NFnftGlTsn777bXP5N7X15esr1+/Pll///33a972pSzPcf6fSrpzguf/093bs38Vgw+gtVQMv7vvl3SyCb0AaKJ6zvl7zez3ZrbFzK7KrSMATVFr+H8kabGkdkklSRvLLWhmPWY2aGblf8wNQNPVFH53P+7u5919VNKPJS1LLNvv7h3u3lFrkwDyV1P4zWzuuIddkt7Jpx0AzXJZpQXMbLukWyV9ycyGJH1f0q1m1i7JJR2V9N0G9gigAfg+P+oya9asZP3uu+8uW6v0WwFm6eHqffv2JeudnZ3J+lTF9/kBJBF+ICjCDwRF+IGgCD8QFOEHgmKoD4X57LPPkvXLLktfhjIyMpKs33HHHWVrr7zySnLdSxlDfQCSCD8QFOEHgiL8QFCEHwiK8ANBEX4gqIrf50dsN9xwQ7J+//33J+s33nhj2VqlcfxKDh06lKzv37+/rtef6tjzA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQjPNPcUuWLEnWe3t7k/V77703WZ8zZ86ke6rW+fPnk/VSqZSsj46O5tnOlMOeHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCqjjOb2bzJW2TNEfSqKR+d/+hmbVJ2iFpoaSjkh5w9w8b12pclcbSu7u7y9YqjeMvXLiwlpZyMTg4mKyvX78+Wd+1a1ee7YRTzZ5/RNK/uftXJX1d0hozu07So5JecvdrJL2UPQZwiagYfncvufuB7P5pSYclzZO0UtLWbLGtku5pVJMA8jepc34zWyjpa5IGJM1295I09gdC0tV5Nwegcaq+tt/MvijpOUnfc/dTZlVNByYz65HUU1t7ABqlqj2/mX1BY8H/mbs/nz193MzmZvW5kk5MtK6797t7h7t35NEwgHxUDL+N7eJ/Iumwu28aV9olaVV2f5Wknfm3B6BRKk7RbWbLJf1G0tsaG+qTpHUaO+//paQFkv4s6VvufrLCa4Wconv27NnJ+nXXXZesP/3008n6tddeO+me8jIwMJCsP/nkk2VrO3em9xd8Jbc21U7RXfGc391/K6nci90+maYAtA6u8AOCIvxAUIQfCIrwA0ERfiAowg8ExU93V6mtra1sra+vL7lue3t7sr5o0aKaesrDa6+9lqxv3LgxWd+zZ0+y/sknn0y6JzQHe34gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCCrMOP9NN92UrK9duzZZX7ZsWdnavHnzauopLx9//HHZ2ubNm5PrPvHEE8n62bNna+oJrY89PxAU4QeCIvxAUIQfCIrwA0ERfiAowg8EFWacv6urq656PQ4dOpSs7969O1kfGRlJ1lPfuR8eHk6ui7jY8wNBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUObu6QXM5kvaJmmOpFFJ/e7+QzN7TNJqSX/NFl3n7r+q8FrpjQGom7tbNctVE/65kua6+wEzmynpDUn3SHpA0hl3f6rapgg/0HjVhr/iFX7uXpJUyu6fNrPDkor96RoAdZvUOb+ZLZT0NUkD2VO9ZvZ7M9tiZleVWafHzAbNbLCuTgHkquJh/98WNPuipFclrXf3581stqQPJLmkH2js1OChCq/BYT/QYLmd80uSmX1B0m5Je9x90wT1hZJ2u/vSCq9D+IEGqzb8FQ/7zcwk/UTS4fHBzz4IvKBL0juTbRJAcar5tH+5pN9IeltjQ32StE5St6R2jR32H5X03ezDwdRrsecHGizXw/68EH6g8XI77AcwNRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCavYU3R9I+r9xj7+UPdeKWrW3Vu1Lorda5dnbP1a7YFO/z/+5jZsNuntHYQ0ktGpvrdqXRG+1Kqo3DvuBoAg/EFTR4e8vePsprdpbq/Yl0VutCumt0HN+AMUpes8PoCCFhN/M7jSzI2b2rpk9WkQP5ZjZUTN728wOFj3FWDYN2gkze2fcc21m9msz+1N2O+E0aQX19piZvZ+9dwfN7F8L6m2+mb1sZofN7A9m9kj2fKHvXaKvQt63ph/2m9k0SX+U1ClpSNLrkrrd/VBTGynDzI5K6nD3wseEzexfJJ2RtO3CbEhm9h+STrr7huwP51Xu/u8t0ttjmuTMzQ3qrdzM0t9Rge9dnjNe56GIPf8ySe+6+3vufk7SLyStLKCPlufu+yWdvOjplZK2Zve3auw/T9OV6a0luHvJ3Q9k909LujCzdKHvXaKvQhQR/nmS/jLu8ZBaa8pvl7TXzN4ws56im5nA7AszI2W3Vxfcz8UqztzcTBfNLN0y710tM17nrYjwTzSbSCsNOXzD3f9Z0l2S1mSHt6jOjyQt1tg0biVJG4tsJptZ+jlJ33P3U0X2Mt4EfRXyvhUR/iFJ88c9/rKkYwX0MSF3P5bdnpD0gsZOU1rJ8QuTpGa3Jwru52/c/bi7n3f3UUk/VoHvXTaz9HOSfubuz2dPF/7eTdRXUe9bEeF/XdI1ZvYVM5su6duSdhXQx+eY2YzsgxiZ2QxJ31TrzT68S9Kq7P4qSTsL7OXvtMrMzeVmllbB712rzXhdyEU+2VDGf0maJmmLu69vehMTMLNFGtvbS2PfePx5kb2Z2XZJt2rsW1/HJX1f0n9L+qWkBZL+LOlb7t70D97K9HarJjlzc4N6Kzez9IAKfO/ynPE6l364wg+IiSv8gKAIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8E9f/Ex0YKZYOZcwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(show_img, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Label\n",
    "train_dataset[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "show_img = train_dataset[1][0].numpy().reshape(28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7ff7c886d3c8>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(show_img, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Label\n",
    "train_dataset[1][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1b: Loading MNIST Test Dataset\n",
    "- Show our algorithm works beyond the data we have trained on.\n",
    "- Out-of-sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_dataset = dsets.MNIST(root='./data', \n",
    "                           train=False, \n",
    "                           transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Image matrix\n",
    "test_dataset[0][0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7ff7c8760b70>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_img = test_dataset[0][0].numpy().reshape(28, 28)\n",
    "plt.imshow(show_img, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Label\n",
    "test_dataset[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Make Dataset Iterable\n",
    "- Aim: make the dataset iterable\n",
    "- **totaldata**: 60000\n",
    "- **minibatch**: 100\n",
    "    - Number of examples in 1 iteration\n",
    "- **iterations**: 3000\n",
    "    - 1 iteration: one mini-batch forward & backward pass\n",
    "- **epochs**\n",
    "    - 1 epoch: running through the whole dataset once\n",
    "    - $epochs = iterations \\div \\frac{totaldata}{minibatch} = 3000 \\div \\frac{60000}{100} = 5 $\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_iters = 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_epochs = n_iters / (len(train_dataset) / batch_size)\n",
    "num_epochs = int(num_epochs)\n",
    "num_epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Iterable Object: Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check Iterability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import collections\n",
    "isinstance(train_loader, collections.Iterable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Iterable Object: Testing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Iterable object\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check Iterability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(test_loader, collections.Iterable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Main Aim: Iterate Through Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_1 = np.ones((28, 28))\n",
    "img_2 = np.ones((28, 28))\n",
    "lst = [img_1, img_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28)\n",
      "(28, 28)\n"
     ]
    }
   ],
   "source": [
    "# Need to iterate\n",
    "# Think of numbers as the images\n",
    "for i in lst:\n",
    "    print(i.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Building Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Same as linear regression! \n",
    "class LogisticRegressionModel(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LogisticRegressionModel, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Instantiate Model Class\n",
    "- Input dimension: \n",
    "    - Size of image\n",
    "    - $28 \\times 28 = 784$\n",
    "- Output dimension: 10\n",
    "    - 0, 1, 2, 3, 4, 5, 6, 7, 8, 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Size of images\n",
    "train_dataset[0][0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_dim = 28*28\n",
    "output_dim = 10\n",
    "\n",
    "model = LogisticRegressionModel(input_dim, output_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Instantiate Loss Class\n",
    "- **Logistic Regression**: Cross Entropy Loss\n",
    "    - _Linear Regression: MSE_\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What happens in `nn.CrossEntropyLoss()`?\n",
    "- Computes softmax (logistic/softmax function)\n",
    "- Computes cross entropy\n",
    "\n",
    "<img src=\"./images/cross_entropy_final_4.png\" alt=\"deeplearningwizard\" style=\"width: 900px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Instantiate Optimizer Class\n",
    "- Simplified equation\n",
    "    - $\\theta = \\theta - \\eta \\cdot \\nabla_\\theta $\n",
    "        - $\\theta$: parameters (our variables)\n",
    "        - $\\eta$: learning rate (how fast we want to learn)\n",
    "        - $\\nabla_\\theta$: parameters' gradients\n",
    "- Even simplier equation\n",
    "    - `parameters = parameters - learning_rate * parameters_gradients`\n",
    "    - **At every iteration, we update our model's parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters In-Depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object Module.parameters at 0x7ff7c884f830>\n",
      "2\n",
      "torch.Size([10, 784])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "print(model.parameters())\n",
    "\n",
    "print(len(list(model.parameters())))\n",
    "\n",
    "# FC 1 Parameters \n",
    "print(list(model.parameters())[0].size())\n",
    "\n",
    "# FC 1 Bias Parameters\n",
    "print(list(model.parameters())[1].size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quick Matrix Product Review\n",
    "- Example 1: **matrix product**\n",
    "    - $A: (100, 10)$\n",
    "    - $B: (10, 1)$\n",
    "    - $A \\cdot B = (100, 10) \\cdot (10, 1) = (100, 1)$\n",
    "- Example 2: **matrix product**\n",
    "    - $A: (50, 5)$\n",
    "    - $B: (5, 2)$\n",
    "    - $A \\cdot B = (50, 5) \\cdot (5, 2) = (50, 2)$\n",
    "- Example 3: **element-wise addition**\n",
    "    - $A: (10, 1)$\n",
    "    - $B: (10, 1)$\n",
    "    - $A + B = (10, 1)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/lr_params2.png\" alt=\"deeplearningwizard\" style=\"width: 900px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Train Model\n",
    "- Process \n",
    "    1. Convert inputs/labels to variables\n",
    "    2. Clear gradient buffets\n",
    "    3. Get output given inputs \n",
    "    4. Get loss\n",
    "    5. Get gradients w.r.t. parameters\n",
    "    6. Update parameters using gradients\n",
    "        - `parameters = parameters - learning_rate * parameters_gradients`\n",
    "    7. REPEAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 500. Loss: 1.8513233661651611. Accuracy: 70\n",
      "Iteration: 1000. Loss: 1.5732524394989014. Accuracy: 77\n",
      "Iteration: 1500. Loss: 1.3840199708938599. Accuracy: 79\n",
      "Iteration: 2000. Loss: 1.1711134910583496. Accuracy: 81\n",
      "Iteration: 2500. Loss: 1.1094708442687988. Accuracy: 82\n",
      "Iteration: 3000. Loss: 1.002761721611023. Accuracy: 82\n"
     ]
    }
   ],
   "source": [
    "iter = 0\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # Load images as Variable\n",
    "        images = images.view(-1, 28*28).requires_grad_()\n",
    "        labels = labels\n",
    "        \n",
    "        # Clear gradients w.r.t. parameters\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass to get output/logits\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # Calculate Loss: softmax --> cross entropy loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Getting gradients w.r.t. parameters\n",
    "        loss.backward()\n",
    "        \n",
    "        # Updating parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        iter += 1\n",
    "        \n",
    "        if iter % 500 == 0:\n",
    "            # Calculate Accuracy         \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            # Iterate through test dataset\n",
    "            for images, labels in test_loader:\n",
    "                # Load images to a Torch Variable\n",
    "                images = images.view(-1, 28*28).requires_grad_()\n",
    "                \n",
    "                # Forward pass only to get logits/output\n",
    "                outputs = model(images)\n",
    "                \n",
    "                # Get predictions from the maximum value\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                \n",
    "                # Total number of labels\n",
    "                total += labels.size(0)\n",
    "                \n",
    "                # Total correct predictions\n",
    "                correct += (predicted == labels).sum()\n",
    "            \n",
    "            accuracy = 100 * correct / total\n",
    "            \n",
    "            # Print Loss\n",
    "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Break Down Accuracy Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OUTPUTS\n",
      "tensor([[-0.4181, -1.0784, -0.4840, -0.0985, -0.2394, -0.1801, -1.1639,\n",
      "          2.9352, -0.1552,  0.8852],\n",
      "        [ 0.5117, -0.1099,  1.5295,  0.8863, -1.8813,  0.5967,  1.3632,\n",
      "         -1.8977,  0.4183, -1.4990],\n",
      "        [-1.0126,  2.4112,  0.2373,  0.0857, -0.7007, -0.2015, -0.3428,\n",
      "         -0.2548,  0.1659, -0.4703],\n",
      "        [ 2.8072, -2.2973, -0.0984, -0.4313, -0.9619,  0.8670,  1.2201,\n",
      "          0.3752, -0.2873, -0.3272],\n",
      "        [-0.0343, -2.0043,  0.5081, -0.6452,  1.8647, -0.6924,  0.1435,\n",
      "          0.4330,  0.2958,  1.0339],\n",
      "        [-1.5392,  2.9070,  0.2297,  0.3139, -0.6863, -0.2734, -0.8377,\n",
      "         -0.1238,  0.3285, -0.3004],\n",
      "        [-1.2037, -1.3739, -0.5947,  0.3530,  1.4205,  0.0593, -0.7307,\n",
      "          0.6642,  0.3937,  0.8004],\n",
      "        [-1.4439, -0.3284, -0.7652, -0.0952,  0.9323,  0.3006,  0.0238,\n",
      "         -0.0810,  0.0612,  1.3295],\n",
      "        [ 0.5409, -0.5266,  0.9914, -1.2369,  0.6583,  0.0992,  0.8525,\n",
      "         -1.0562,  0.2013,  0.0462],\n",
      "        [-0.6548, -0.7253, -0.9825, -1.1663,  0.9076, -0.0694, -0.3708,\n",
      "          1.8270,  0.2457,  1.5921],\n",
      "        [ 3.2147, -1.7689,  0.8531,  1.2320, -0.8126,  1.1251, -0.2776,\n",
      "         -1.4244,  0.5930, -1.6183],\n",
      "        [ 0.7470, -0.5545,  1.0251,  0.0529,  0.4384, -0.5934,  0.7666,\n",
      "         -1.0084,  0.5313, -0.3465],\n",
      "        [-0.7916, -1.7064, -0.7805, -1.1588,  1.3284, -0.1708, -0.2092,\n",
      "          0.9495,  0.1033,  2.0208],\n",
      "        [ 3.0602, -2.3578, -0.2576, -0.2198, -0.2372,  0.9765, -0.1514,\n",
      "         -0.5380,  0.7970,  0.1374],\n",
      "        [-1.2613,  2.8594, -0.0874,  0.1974, -1.2018, -0.0064, -0.0923,\n",
      "         -0.2142,  0.2575, -0.3218],\n",
      "        [ 0.4348, -0.7216,  0.0021,  1.2864, -0.5062,  0.7761, -0.3236,\n",
      "         -0.5667,  0.5431, -0.7781],\n",
      "        [-0.2157, -2.0200,  0.1829, -0.6882,  1.3815, -0.7609, -0.0902,\n",
      "          0.8647,  0.3679,  1.8843],\n",
      "        [ 0.0950, -1.5009, -0.6347,  0.3662, -0.4679, -0.0359, -0.7671,\n",
      "          2.7155, -0.3991,  0.5737],\n",
      "        [-0.7005, -0.5366, -0.0434,  1.1289, -0.5873,  0.2555,  0.8187,\n",
      "         -0.6557,  0.1241, -0.4297],\n",
      "        [-1.0635, -1.5991, -0.4677, -0.1231,  2.0445,  0.1128, -0.1825,\n",
      "          0.1075,  0.0348,  1.4317],\n",
      "        [-1.0319, -0.1595, -1.3415,  0.1095,  0.5339,  0.1973, -1.3272,\n",
      "          1.5765,  0.4784,  1.4176],\n",
      "        [-0.4928, -1.5653, -0.0672,  0.3325,  0.5359,  0.5368,  2.1542,\n",
      "         -1.4276,  0.3605,  0.0587],\n",
      "        [-0.4761,  0.2958,  0.6597, -0.2658,  1.1279, -1.0676,  1.2506,\n",
      "         -0.2059, -0.1489,  0.1051],\n",
      "        [-0.0764, -0.9274, -0.6838,  0.3464, -0.2656,  1.4099,  0.4486,\n",
      "         -0.9527,  0.5682,  0.0156],\n",
      "        [-0.6900, -0.9611,  0.1395, -0.0079,  1.5424, -0.3208, -0.2682,\n",
      "          0.3586, -0.2771,  1.0389],\n",
      "        [ 4.3606, -2.8621,  0.6310, -0.9657, -0.2486,  1.2009,  1.1873,\n",
      "         -0.8255, -0.2103, -1.2172],\n",
      "        [-0.1000, -1.4268, -0.4627, -0.1041,  0.2959, -0.1392, -0.6855,\n",
      "          1.8622, -0.2580,  1.1347],\n",
      "        [-0.3625, -2.1323, -0.2224, -0.8754,  2.4684,  0.0295,  0.1161,\n",
      "         -0.2660,  0.3037,  1.4570],\n",
      "        [ 2.8688, -2.4517,  0.1782,  1.1149, -1.0898,  1.1062, -0.0681,\n",
      "         -0.5697,  0.8888, -0.6965],\n",
      "        [-1.0429,  1.4446, -0.3349,  0.1254, -0.5017,  0.2286,  0.2328,\n",
      "         -0.3290,  0.3949, -0.2586],\n",
      "        [-0.8476, -0.0004, -1.1003,  2.2806, -1.2226,  0.9251, -0.3165,\n",
      "          0.4957,  0.0690,  0.0232],\n",
      "        [-0.9108,  1.1355, -0.2715,  0.2233, -0.3681,  0.1442, -0.0001,\n",
      "         -0.0174,  0.1454,  0.2286],\n",
      "        [-1.0663, -0.8466, -0.7147,  2.5685, -0.2090,  1.2993, -0.3057,\n",
      "         -0.8314,  0.7046, -0.0176],\n",
      "        [ 1.7013, -1.8051,  0.7541, -1.5248,  0.8972,  0.1518,  1.4876,\n",
      "         -0.8454, -0.2022, -0.2829],\n",
      "        [-0.8179, -0.1239,  0.8630, -0.2137, -0.2275, -0.5411, -1.3448,\n",
      "          1.7354,  0.7751,  0.6234],\n",
      "        [ 0.6515, -1.0431,  2.7165,  0.1873, -1.0623,  0.1286,  0.3597,\n",
      "         -0.2739,  0.3871, -1.6699],\n",
      "        [-0.2828, -1.4663,  0.1182, -0.0896, -0.3640, -0.5129, -0.4905,\n",
      "          2.2914, -0.2227,  0.9463],\n",
      "        [-1.2596,  2.0468, -0.4405, -0.0411, -0.8073,  0.0490, -0.0604,\n",
      "         -0.1206,  0.3504, -0.1059],\n",
      "        [ 0.6089,  0.5885,  0.7898,  1.1318, -1.9008,  0.5875,  0.4227,\n",
      "         -1.1815,  0.5652, -1.3590],\n",
      "        [-1.4551,  2.9537, -0.2805,  0.2372, -1.4180,  0.0297, -0.1515,\n",
      "         -0.6111,  0.6140, -0.3354],\n",
      "        [-0.7182,  1.6778,  0.0553,  0.0461, -0.5446, -0.0338, -0.0215,\n",
      "         -0.0881,  0.1506, -0.2107],\n",
      "        [-0.8027, -0.7854, -0.1275, -0.3177, -0.1600, -0.1964, -0.6084,\n",
      "          2.1285, -0.1815,  1.1911],\n",
      "        [-2.0656, -0.4959, -0.1154, -0.1363,  2.2426, -0.7441, -0.8413,\n",
      "          0.4675,  0.3269,  1.7279],\n",
      "        [-0.3004,  1.0166,  1.1175, -0.0618, -0.0937, -0.4221,  0.1943,\n",
      "         -1.1020,  0.3670, -0.4683],\n",
      "        [-1.0720,  0.2252,  0.0175,  1.3644, -0.7409,  0.4655,  0.5439,\n",
      "          0.0380,  0.1279, -0.2302],\n",
      "        [ 0.2409, -1.2622, -0.6336,  1.8240, -0.5951,  1.3408,  0.2130,\n",
      "         -1.3789,  0.8363, -0.2101],\n",
      "        [-1.3849,  0.3773, -0.0585,  0.6896, -0.0998,  0.2804,  0.0696,\n",
      "         -0.2529,  0.3143,  0.3409],\n",
      "        [-0.9103, -0.1578,  1.6673, -0.4817,  0.4088, -0.5484,  0.6103,\n",
      "         -0.2287, -0.0665,  0.0055],\n",
      "        [-1.1692, -2.8531, -1.2499, -0.0257,  2.8580,  0.2616, -0.7122,\n",
      "         -0.0551,  0.8112,  2.3233],\n",
      "        [-0.2790, -1.9494,  0.6096, -0.5653,  2.2792, -1.0687,  0.1634,\n",
      "          0.3122,  0.1053,  1.0884],\n",
      "        [ 0.1267, -1.2297, -0.1315,  0.2428, -0.5436,  0.4123,  2.3060,\n",
      "         -0.9278, -0.1528, -0.4224],\n",
      "        [-0.0235, -0.9137, -0.1457,  1.6858, -0.7552,  0.7293,  0.2510,\n",
      "         -0.3955, -0.2187, -0.1505],\n",
      "        [ 0.5643, -1.2783, -1.4149,  0.0304,  0.8375,  1.5018,  0.0338,\n",
      "         -0.3875, -0.0117,  0.5751],\n",
      "        [ 0.2926, -0.7486, -0.3238,  1.0384,  0.0308,  0.6792, -0.0170,\n",
      "         -0.5797,  0.2819, -0.3510],\n",
      "        [ 0.1219, -0.5862,  1.5817, -0.1297,  0.4730, -0.9171,  0.7886,\n",
      "         -0.7022, -0.0501, -0.2812],\n",
      "        [ 1.7587, -2.4511, -0.7369,  0.4082, -0.6426,  1.1784,  0.6052,\n",
      "         -0.7178,  1.6161, -0.2220],\n",
      "        [-0.1267, -2.6719,  0.0505, -0.4972,  2.9027, -0.1461,  0.2807,\n",
      "         -0.2921,  0.2231,  1.1327],\n",
      "        [-0.9892,  2.4401,  0.1274,  0.2838, -0.7535, -0.1684, -0.6493,\n",
      "         -0.1908,  0.2290, -0.2150],\n",
      "        [-0.2071, -2.1351, -0.9191, -0.9309,  1.7747, -0.3046,  0.0183,\n",
      "          1.0136, -0.1016,  2.1288],\n",
      "        [-0.0103,  0.3280, -0.6974, -0.2504,  0.3187,  0.4390, -0.1879,\n",
      "          0.3954,  0.2332, -0.1971],\n",
      "        [-0.2280, -1.6754, -0.7438,  0.5078,  0.2544, -0.1020, -0.2503,\n",
      "          2.0799, -0.5033,  0.5890],\n",
      "        [ 0.3972, -0.9369,  1.2696, -1.6713, -0.4159, -0.0221,  0.6489,\n",
      "         -0.4777,  1.2497,  0.3931],\n",
      "        [-0.7566, -0.8230, -0.0785, -0.3083,  0.7821,  0.1880,  0.1037,\n",
      "         -0.0956,  0.4219,  1.0798],\n",
      "        [-1.0328, -0.1700,  1.3806,  0.5445, -0.2624, -0.0780, -0.3595,\n",
      "         -0.6253,  0.4309,  0.1813],\n",
      "        [-1.0360, -0.4704,  0.1948, -0.7066,  0.6600, -0.4633, -0.3602,\n",
      "          1.7494,  0.1522,  0.6086],\n",
      "        [-1.2032, -0.7903, -0.5754,  0.4722,  0.6068,  0.5752,  0.2151,\n",
      "         -0.2495,  0.3420,  0.9278],\n",
      "        [ 0.2247, -0.1361,  0.9374, -0.1543,  0.4921, -0.6553,  0.5885,\n",
      "          0.2617, -0.2216, -0.3736],\n",
      "        [-0.2867, -1.4486,  0.6658, -0.8755,  2.3195, -0.7627, -0.2132,\n",
      "          0.2488,  0.3484,  1.0860],\n",
      "        [-1.4031, -0.4518, -0.3181,  2.8268, -0.5371,  1.0154, -0.9247,\n",
      "         -0.7385,  1.1031,  0.0422],\n",
      "        [ 2.8604, -1.5413,  0.6241, -0.8017, -1.4104,  0.6314,  0.4614,\n",
      "         -0.0218, -0.3411, -0.2609],\n",
      "        [ 0.2113, -1.2348, -0.8535, -0.1041, -0.2703, -0.1294, -0.7057,\n",
      "          2.7552, -0.4429,  0.4517],\n",
      "        [ 4.5191, -2.7407,  1.1091,  0.3975, -0.9456,  1.2277,  0.3616,\n",
      "         -1.6564,  0.5063, -1.4274],\n",
      "        [ 1.4615, -1.0765,  1.8388,  1.5006, -1.2351,  0.2781,  0.2830,\n",
      "         -0.8491,  0.2222, -1.7779],\n",
      "        [-1.2160,  0.8502,  0.2413, -0.0798, -0.7880, -0.4286, -0.8060,\n",
      "          0.7194,  1.2663,  0.6412],\n",
      "        [-1.3318,  2.3388, -0.4003, -0.1094, -1.0285,  0.1021, -0.0388,\n",
      "         -0.0497,  0.5137, -0.2507],\n",
      "        [-1.7853,  0.5884, -0.6108, -0.5557,  0.8696, -0.6226, -0.7983,\n",
      "          1.7169, -0.0145,  0.8231],\n",
      "        [-0.1739,  0.1562, -0.2933,  2.3195, -0.9480,  1.2019, -0.4834,\n",
      "         -1.0567,  0.5685, -0.6841],\n",
      "        [-0.7920, -0.3339,  0.7452, -0.6529, -0.3307, -0.6092, -0.0950,\n",
      "          1.7311, -0.3481,  0.3801],\n",
      "        [-1.7810,  1.0676, -0.7611,  0.3658, -0.0431, -0.1012, -0.6048,\n",
      "          0.3089,  0.9998,  0.7164],\n",
      "        [-0.5856, -0.5261, -0.4859, -1.0551, -0.1838, -0.2144, -1.2599,\n",
      "          3.3891,  0.4691,  0.7566],\n",
      "        [-0.4984, -1.7770, -1.1998, -0.1075,  1.0882,  0.4539, -0.5651,\n",
      "          1.4381, -0.5678,  1.7479],\n",
      "        [ 0.2938, -1.8536,  0.4259, -0.5429,  0.0066,  0.4120,  2.3793,\n",
      "         -0.3666, -0.2604,  0.0382],\n",
      "        [-0.4080, -0.9851,  4.0264,  0.1099, -0.1766, -1.1557,  0.6419,\n",
      "         -0.8147,  0.7535, -1.1452],\n",
      "        [-0.4636, -1.7323, -0.6433, -0.0274,  0.7227, -0.1799, -0.9336,\n",
      "          2.1881, -0.2073,  1.6522],\n",
      "        [-0.9617, -0.0348, -0.3980, -0.4738,  0.7790,  0.4671, -0.6115,\n",
      "         -0.7067,  1.3036,  0.4923],\n",
      "        [-1.0151, -2.5385, -0.6072,  0.2902,  3.1570,  0.1062, -0.2169,\n",
      "         -0.4491,  0.6326,  1.6829],\n",
      "        [-1.8852,  0.6066, -0.2840, -0.4475, -0.1147, -0.7858, -1.1805,\n",
      "          3.0723,  0.3960,  0.9720],\n",
      "        [ 0.0344, -1.4878, -0.9675,  1.9649, -0.3146,  1.2183,  0.6730,\n",
      "         -0.3650,  0.0646, -0.0898],\n",
      "        [-0.2118, -2.0350,  0.9917, -0.8993,  1.2334, -0.6723,  2.5847,\n",
      "         -0.0454, -0.4149,  0.3927],\n",
      "        [-1.7365,  3.0447,  0.5115,  0.0786, -0.7544, -0.2158, -0.4876,\n",
      "         -0.2891,  0.5089, -0.6719],\n",
      "        [ 0.3652, -0.5457, -0.1167,  2.9056, -1.1622,  0.8192, -1.3245,\n",
      "         -0.6414,  0.8097, -0.4958],\n",
      "        [-0.8755, -0.6983,  0.2208, -0.6463,  0.5276,  0.1145,  2.7229,\n",
      "         -1.0316,  0.1905,  0.2090],\n",
      "        [-0.9702,  0.1265, -0.0007, -0.5106,  0.4970, -0.0804,  0.0017,\n",
      "          0.0607,  0.6164,  0.4490],\n",
      "        [-0.8271, -0.6822, -0.7434,  2.6457, -1.6143,  1.1486, -1.0705,\n",
      "          0.5611,  0.6422,  0.1250],\n",
      "        [-1.9979,  1.8175, -0.1658, -0.0343, -0.6292,  0.1774,  0.3150,\n",
      "         -0.4633,  0.9266,  0.0252],\n",
      "        [-0.9039, -0.6030, -0.2173, -1.1768,  2.3198, -0.5072,  0.3418,\n",
      "         -0.1551,  0.1282,  1.4250],\n",
      "        [-0.9891,  0.5212, -0.4518,  0.3267, -0.0759,  0.3826, -0.0341,\n",
      "          0.0382,  0.2451,  0.3658],\n",
      "        [-2.1217,  1.5102, -0.7828,  0.3554, -0.4192, -0.0772,  0.0578,\n",
      "          0.8070,  0.1701,  0.5880],\n",
      "        [ 1.0665, -1.3826,  0.6243, -0.8096, -0.4227,  0.5925,  1.8112,\n",
      "         -0.9946,  0.2010, -0.7731],\n",
      "        [-1.1263, -1.7484,  0.0041, -0.5439,  1.7242, -0.9475, -0.3835,\n",
      "          0.8452,  0.3077,  2.2689]])\n"
     ]
    }
   ],
   "source": [
    "iter_test = 0\n",
    "for images, labels in test_loader:\n",
    "    iter_test += 1\n",
    "    images = images.view(-1, 28*28).requires_grad_()\n",
    "    outputs = model(images)\n",
    "    if iter_test == 1:\n",
    "        print('OUTPUTS')\n",
    "        print(outputs)\n",
    "    _, predicted = torch.max(outputs.data, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OUTPUTS\n",
      "torch.Size([100, 10])\n"
     ]
    }
   ],
   "source": [
    "iter_test = 0\n",
    "for images, labels in test_loader:\n",
    "    iter_test += 1\n",
    "    images = images.view(-1, 28*28).requires_grad_()\n",
    "    outputs = model(images)\n",
    "    if iter_test == 1:\n",
    "        print('OUTPUTS')\n",
    "        print(outputs.size())\n",
    "    _, predicted = torch.max(outputs.data, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OUTPUTS\n",
      "tensor([-0.4181, -1.0784, -0.4840, -0.0985, -0.2394, -0.1801, -1.1639,\n",
      "         2.9352, -0.1552,  0.8852])\n"
     ]
    }
   ],
   "source": [
    "iter_test = 0\n",
    "for images, labels in test_loader:\n",
    "    iter_test += 1\n",
    "    images = images.view(-1, 28*28).requires_grad_()\n",
    "    outputs = model(images)\n",
    "    if iter_test == 1:\n",
    "        print('OUTPUTS')\n",
    "        print(outputs[0, :])\n",
    "    _, predicted = torch.max(outputs.data, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDICTION\n",
      "torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "iter_test = 0\n",
    "for images, labels in test_loader:\n",
    "    iter_test += 1\n",
    "    images = images.view(-1, 28*28).requires_grad_()\n",
    "    outputs = model(images)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    if iter_test == 1:\n",
    "        print('PREDICTION')\n",
    "        print(predicted.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDICTION\n",
      "tensor(7)\n"
     ]
    }
   ],
   "source": [
    "iter_test = 0\n",
    "for images, labels in test_loader:\n",
    "    iter_test += 1\n",
    "    images = images.view(-1, 28*28).requires_grad_()\n",
    "    outputs = model(images)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    if iter_test == 1:\n",
    "        print('PREDICTION')\n",
    "        print(predicted[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDICTION\n",
      "tensor(7)\n",
      "LABEL SIZE\n",
      "torch.Size([100])\n",
      "LABEL FOR IMAGE 0\n",
      "tensor(7)\n"
     ]
    }
   ],
   "source": [
    "iter_test = 0\n",
    "for images, labels in test_loader:\n",
    "    iter_test += 1\n",
    "    images = images.view(-1, 28*28).requires_grad_()\n",
    "    outputs = model(images)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    if iter_test == 1:\n",
    "        print('PREDICTION')\n",
    "        print(predicted[0])\n",
    "        \n",
    "        print('LABEL SIZE')\n",
    "        print(labels.size())\n",
    "        \n",
    "        print('LABEL FOR IMAGE 0')\n",
    "        print(labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDICTION\n",
      "tensor(2)\n",
      "LABEL SIZE\n",
      "torch.Size([100])\n",
      "LABEL FOR IMAGE 1\n",
      "tensor(2)\n"
     ]
    }
   ],
   "source": [
    "iter_test = 0\n",
    "for images, labels in test_loader:\n",
    "    iter_test += 1\n",
    "    images = images.view(-1, 28*28).requires_grad_()\n",
    "    outputs = model(images)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    \n",
    "    if iter_test == 1:\n",
    "        print('PREDICTION')\n",
    "        print(predicted[1])\n",
    "        \n",
    "        print('LABEL SIZE')\n",
    "        print(labels.size())\n",
    "        \n",
    "        print('LABEL FOR IMAGE 1')\n",
    "        print(labels[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82.94\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "iter_test = 0\n",
    "for images, labels in test_loader:\n",
    "    iter_test += 1\n",
    "    images = images.view(-1, 28*28).requires_grad_()\n",
    "    outputs = model(images)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    \n",
    "    # Total number of labels\n",
    "    total += labels.size(0)\n",
    "\n",
    "    # Total correct predictions\n",
    "    correct += (predicted == labels).sum()\n",
    "\n",
    "accuracy = 100 * (correct.item() / total)\n",
    "\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[ True  True  True  True  True  True  True  True  True  True]\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "# Explaining .sum() python built-in function\n",
    "# correct += (predicted == labels).sum()\n",
    "import numpy as np\n",
    "a = np.ones((10))\n",
    "print(a)\n",
    "b = np.ones((10))\n",
    "print(b)\n",
    "\n",
    "print(a == b)\n",
    "\n",
    "print((a == b).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_model = False\n",
    "if save_model is True:\n",
    "    # Saves only parameters\n",
    "    torch.save(model.state_dict(), 'awesome_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Building a Logistic Regression Model with PyTorch (GPU)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CPU Version**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 500. Loss: 1.876196026802063. Accuracy: 64.44\n",
      "Iteration: 1000. Loss: 1.5153584480285645. Accuracy: 75.68\n",
      "Iteration: 1500. Loss: 1.3521136045455933. Accuracy: 78.98\n",
      "Iteration: 2000. Loss: 1.2136967182159424. Accuracy: 80.95\n",
      "Iteration: 2500. Loss: 1.0934826135635376. Accuracy: 81.97\n",
      "Iteration: 3000. Loss: 1.024120569229126. Accuracy: 82.49\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "\n",
    "'''\n",
    "STEP 1: LOADING DATASET\n",
    "'''\n",
    "\n",
    "train_dataset = dsets.MNIST(root='./data', \n",
    "                            train=True, \n",
    "                            transform=transforms.ToTensor(),\n",
    "                            download=True)\n",
    "\n",
    "test_dataset = dsets.MNIST(root='./data', \n",
    "                           train=False, \n",
    "                           transform=transforms.ToTensor())\n",
    "\n",
    "'''\n",
    "STEP 2: MAKING DATASET ITERABLE\n",
    "'''\n",
    "\n",
    "batch_size = 100\n",
    "n_iters = 3000\n",
    "num_epochs = n_iters / (len(train_dataset) / batch_size)\n",
    "num_epochs = int(num_epochs)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)\n",
    "\n",
    "'''\n",
    "STEP 3: CREATE MODEL CLASS\n",
    "'''\n",
    "class LogisticRegressionModel(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(LogisticRegressionModel, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out\n",
    "\n",
    "'''\n",
    "STEP 4: INSTANTIATE MODEL CLASS\n",
    "'''\n",
    "input_dim = 28*28\n",
    "output_dim = 10\n",
    "\n",
    "model = LogisticRegressionModel(input_dim, output_dim)\n",
    "\n",
    "'''\n",
    "STEP 5: INSTANTIATE LOSS CLASS\n",
    "'''\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "'''\n",
    "STEP 6: INSTANTIATE OPTIMIZER CLASS\n",
    "'''\n",
    "learning_rate = 0.001\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "'''\n",
    "STEP 7: TRAIN THE MODEL\n",
    "'''\n",
    "iter = 0\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # Load images as Variable\n",
    "        images = images.view(-1, 28*28).requires_grad_()\n",
    "        labels = labels\n",
    "        \n",
    "        # Clear gradients w.r.t. parameters\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass to get output/logits\n",
    "        # 100 x 10\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # Calculate Loss: softmax --> cross entropy loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Getting gradients w.r.t. parameters\n",
    "        loss.backward()\n",
    "        \n",
    "        # Updating parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        iter += 1\n",
    "        \n",
    "        if iter % 500 == 0:\n",
    "            # Calculate Accuracy         \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            # Iterate through test dataset\n",
    "            for images, labels in test_loader:\n",
    "                # Load images to a Torch Variable\n",
    "                images = images.view(-1, 28*28).requires_grad_()\n",
    "                \n",
    "                # Forward pass only to get logits/output\n",
    "                outputs = model(images)\n",
    "                \n",
    "                # Get predictions from the maximum value\n",
    "                # 100 x 1\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                \n",
    "                # Total number of labels\n",
    "                total += labels.size(0)\n",
    "                \n",
    "                # Total correct predictions\n",
    "                correct += (predicted == labels).sum()\n",
    "            \n",
    "            accuracy = 100 * correct.item() / total\n",
    "            \n",
    "            # Print Loss\n",
    "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPU: 2 things must be on GPU\n",
    "- `model`\n",
    "- `variables`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 500. Loss: 1.8571407794952393. Accuracy: 68.99\n",
      "Iteration: 1000. Loss: 1.5415704250335693. Accuracy: 75.86\n",
      "Iteration: 1500. Loss: 1.2755383253097534. Accuracy: 78.92\n",
      "Iteration: 2000. Loss: 1.2468739748001099. Accuracy: 80.72\n",
      "Iteration: 2500. Loss: 1.0708973407745361. Accuracy: 81.73\n",
      "Iteration: 3000. Loss: 1.0359245538711548. Accuracy: 82.74\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "\n",
    "'''\n",
    "STEP 1: LOADING DATASET\n",
    "'''\n",
    "\n",
    "train_dataset = dsets.MNIST(root='./data', \n",
    "                            train=True, \n",
    "                            transform=transforms.ToTensor(),\n",
    "                            download=True)\n",
    "\n",
    "test_dataset = dsets.MNIST(root='./data', \n",
    "                           train=False, \n",
    "                           transform=transforms.ToTensor())\n",
    "\n",
    "'''\n",
    "STEP 2: MAKING DATASET ITERABLE\n",
    "'''\n",
    "\n",
    "batch_size = 100\n",
    "n_iters = 3000\n",
    "num_epochs = n_iters / (len(train_dataset) / batch_size)\n",
    "num_epochs = int(num_epochs)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)\n",
    "\n",
    "'''\n",
    "STEP 3: CREATE MODEL CLASS\n",
    "'''\n",
    "class LogisticRegressionModel(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(LogisticRegressionModel, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out\n",
    "\n",
    "'''\n",
    "STEP 4: INSTANTIATE MODEL CLASS\n",
    "'''\n",
    "input_dim = 28*28\n",
    "output_dim = 10\n",
    "\n",
    "model = LogisticRegressionModel(input_dim, output_dim)\n",
    "\n",
    "#######################\n",
    "#  USE GPU FOR MODEL  #\n",
    "#######################\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "'''\n",
    "STEP 5: INSTANTIATE LOSS CLASS\n",
    "'''\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "'''\n",
    "STEP 6: INSTANTIATE OPTIMIZER CLASS\n",
    "'''\n",
    "learning_rate = 0.001\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "'''\n",
    "STEP 7: TRAIN THE MODEL\n",
    "'''\n",
    "iter = 0\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        \n",
    "        #######################\n",
    "        #  USE GPU FOR MODEL  #\n",
    "        #######################\n",
    "        images = images.view(-1, 28*28).requires_grad_().to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Clear gradients w.r.t. parameters\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass to get output/logits\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # Calculate Loss: softmax --> cross entropy loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Getting gradients w.r.t. parameters\n",
    "        loss.backward()\n",
    "        \n",
    "        # Updating parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        iter += 1\n",
    "        \n",
    "        if iter % 500 == 0:\n",
    "            # Calculate Accuracy         \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            # Iterate through test dataset\n",
    "            for images, labels in test_loader:\n",
    "                #######################\n",
    "                #  USE GPU FOR MODEL  #\n",
    "                #######################\n",
    "                images = images.view(-1, 28*28).to(device)\n",
    "                \n",
    "                # Forward pass only to get logits/output\n",
    "                outputs = model(images)\n",
    "                \n",
    "                # Get predictions from the maximum value\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                \n",
    "                # Total number of labels\n",
    "                total += labels.size(0)\n",
    "                \n",
    "                #######################\n",
    "                #  USE GPU FOR MODEL  #\n",
    "                #######################\n",
    "                # Total correct predictions\n",
    "                if torch.cuda.is_available():\n",
    "                    correct += (predicted.cpu() == labels.cpu()).sum()\n",
    "                else:\n",
    "                    correct += (predicted == labels).sum()\n",
    "            \n",
    "            accuracy = 100 * correct.item() / total\n",
    "            \n",
    "            # Print Loss\n",
    "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Logistic regression** basics\n",
    "- **Problems** of **linear regression**\n",
    "- **In-depth** Logistic Regression\n",
    "    1. Get logits\n",
    "    2. Get softmax\n",
    "    3. Get cross-entropy loss\n",
    "- **Aim**: reduce cross-entropy loss\n",
    "- Built a **logistic regression model** in **CPU and GPU**\n",
    "    - Step 1: Load Dataset\n",
    "    - Step 2: Make Dataset Iterable\n",
    "    - Step 3: Create Model Class\n",
    "    - Step 4: Instantiate Model Class\n",
    "    - Step 5: Instantiate Loss Class\n",
    "    - Step 6: Instantiate Optimizer Class\n",
    "    - Step 7: Train Model\n",
    "- Important things to be on **GPU**\n",
    "    - `model`\n",
    "    - `tensors with gradients`"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
